# Safe Preference Learning with Weighted Signal Temporal Logic (SPL_WSTL)

Welcome to the repository for "Safe Preference Learning using Weighted Signal Temporal Logic."

## Overview
This repository houses the codebase implementing the approach described in the paper titled [A Safe Preference Learning Approach for Personalization with Applications to Autonomous Vehicles](https://arxiv.org/abs/2311.02099). This work is funded by the Toyota Research Institute.


## Contents

### 1. WSTL setup and the learning framework
- The core implementation of Weighted Signal Temporal Logic can be explored in './lib/WSTL.py'.
- The learning framework is provided in the "./lib/learners.py".

### 2. Experiments
- Explore the experiments conducted in the paper in the './experiments' directory.
- Refer to [this guide](./experiments/readme.md) for detailed instructions on conducting experiments.

### 3. Data
- Find the datasets used in the experiments in './data.'
- The human subject study is conducted under the IRB Protocol No. HUM00221976.
- For more details on the data, check [this guide](./data/readme.md).

## Getting Started

To get started with the codebase, check out the 'demo.ipynb' file, which provides a walkthrough of the WSTL code.

## Note on Sponsorship

This work is sponsored by the Toyota Research Institute.

For more information on the methodology and specifics of the implementation, please refer to the linked paper.

Feel free to explore and contribute to this repository. Your feedback and contributions are highly appreciated!
